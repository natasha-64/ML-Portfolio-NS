{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfce0527",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;\"><span style=\"color:blue;\">Reinforcement Learning with OpenAI Gym</span></h1><br />\n",
    "\n",
    "<center><img src =\"area-51.jpg\" width=\"500\" /></center>\n",
    "\n",
    "- **A** - Action\n",
    "- **R** - Reward\n",
    "- **E** - Environment\n",
    "- **A** - Agent\n",
    "\n",
    "<img src=\"RL_illustration.png\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cca4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries {!pip install as needed}\n",
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "import pygame import gfxdraw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e22b35",
   "metadata": {},
   "source": [
    "## Create an Environment for our Cart Pole\n",
    "\n",
    "[gymnasium.Env](https://gymnasium.farama.org/api/env/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fcbfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1', render_mode='human')\n",
    "\n",
    "(state,_) = env.reset() # Initialises all variables to a ground state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7c783a",
   "metadata": {},
   "source": [
    "### The States - what is happening in each frame\n",
    "\n",
    "<img src=\"cart-states.png\" />\n",
    "\n",
    "#### Four States\n",
    "\n",
    "1. x Position of the cart\n",
    "2. &#7819; Velocity of the cart\n",
    "3. &#952; Pole angle\n",
    "4. &#952; Angular Velocity (Theta dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc4dbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b17b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push the cart in one direction (0 = left)\n",
    "env.step(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa26c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation space limits\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upper limit\n",
    "env.observation_space.high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67848da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower limit\n",
    "env.observation_space.low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb20c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# action space\n",
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc684a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All specifications\n",
    "env.spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3931ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of steps per episode\n",
    "env.spec.max_episode_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa0f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward threshold per episode\n",
    "env.spec.reward_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f4b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the environment\n",
    "episodeNumber=10000\n",
    "timeSteps=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6709a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation\n",
    "for episodeIndex in range(episodeNumber):\n",
    "    initial_state=env.reset()\n",
    "    print(episodeIndex)\n",
    "    appendedObservations = []\n",
    "    for timeIndex in range(timeSteps):\n",
    "        print(timeIndex)\n",
    "        random_action = env.action_space.sample()\n",
    "        observation, reward, terminated, truncated, info = env.step(random_action)\n",
    "        appendedObservations.append(observation)\n",
    "        time.sleep(0.01) # creates slight delay to allow simulation to run\n",
    "        if (terminated):\n",
    "            time.sleep(0.1)\n",
    "            break\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
